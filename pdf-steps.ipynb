{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import yaml\n",
    "import time\n",
    "import pytz\n",
    "import datetime\n",
    "import argparse\n",
    "import shutil\n",
    "import torch\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "from paddleocr import draw_ocr\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from ultralytics import YOLO\n",
    "from unimernet.common.config import Config\n",
    "import unimernet.tasks as tasks\n",
    "from unimernet.processors import load_processor\n",
    "from struct_eqtable import build_model\n",
    "\n",
    "from modules.latex2png import tex2pil, zhtext2pil\n",
    "from modules.extract_pdf import load_pdf_fitz\n",
    "from modules.layoutlmv3.model_init import Layoutlmv3_Predictor\n",
    "from modules.self_modify import ModifiedPaddleOCR\n",
    "from modules.post_process import get_croped_image, latex_rm_whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-01 18:11:50\n",
      "Started!\n"
     ]
    }
   ],
   "source": [
    "def mfd_model_init(weight):\n",
    "    mfd_model = YOLO(weight)\n",
    "    return mfd_model\n",
    "\n",
    "\n",
    "def mfr_model_init(weight_dir, device='cpu'):\n",
    "    args = argparse.Namespace(cfg_path=\"modules/UniMERNet/configs/demo.yaml\", options=None)\n",
    "    cfg = Config(args)\n",
    "    cfg.config.model.pretrained = os.path.join(weight_dir, \"pytorch_model.bin\")\n",
    "    cfg.config.model.model_config.model_name = weight_dir\n",
    "    cfg.config.model.tokenizer_config.path = weight_dir\n",
    "    task = tasks.setup_task(cfg)\n",
    "    model = task.build_model(cfg)\n",
    "    model = model.to(device)\n",
    "    vis_processor = load_processor('formula_image_eval', cfg.config.datasets.formula_rec_eval.vis_processor.eval)\n",
    "    return model, vis_processor\n",
    "\n",
    "def layout_model_init(weight):\n",
    "    model = Layoutlmv3_Predictor(weight)\n",
    "    return model\n",
    "\n",
    "def tr_model_init(weight, max_time, device='cuda'):\n",
    "    tr_model = build_model(weight, max_new_tokens=4096, max_time=max_time)\n",
    "    if device == 'cuda':\n",
    "        tr_model = tr_model.cuda()\n",
    "    return tr_model\n",
    "\n",
    "args = argparse.Namespace(\n",
    "    pdf='./test_data/',\n",
    "    output='output',\n",
    "    batch_size=1,\n",
    "    vis=True,\n",
    "    render=False\n",
    ")\n",
    "tz = pytz.timezone('Asia/Shanghai')\n",
    "now = datetime.datetime.now(tz)\n",
    "print(now.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "print('Started!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('configs/model_configs.yaml') as f:\n",
    "    model_configs = yaml.load(f, Loader=yaml.FullLoader)\n",
    "img_size = model_configs['model_args']['img_size']\n",
    "conf_thres = model_configs['model_args']['conf_thres']\n",
    "iou_thres = model_configs['model_args']['iou_thres']\n",
    "device = model_configs['model_args']['device']\n",
    "dpi = model_configs['model_args']['pdf_dpi']\n",
    "\n",
    "tr_model = tr_model_init(model_configs['model_args']['tr_weight'], max_time=model_configs['model_args']['table_max_time'], device=device)\n",
    "layout_model = layout_model_init(model_configs['model_args']['layout_weight'])\n",
    "ocr_model = ModifiedPaddleOCR(show_log=True)\n",
    "print(now.strftime('%Y-%m-%d %H:%M:%S'))\n",
    "print('Model init done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total files: 1\n",
      "pdf index: 0 pages: 3\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "if os.path.isdir(args.pdf):\n",
    "    all_pdfs = [os.path.join(args.pdf, name) for name in os.listdir(args.pdf)]\n",
    "else:\n",
    "    all_pdfs = [args.pdf]\n",
    "print(\"total files:\", len(all_pdfs))\n",
    "for idx, single_pdf in enumerate(all_pdfs):\n",
    "    try:\n",
    "        img_list = load_pdf_fitz(single_pdf, dpi=dpi)\n",
    "    except:\n",
    "        img_list = None\n",
    "        print(\"unexpected pdf file:\", single_pdf)\n",
    "    if img_list is None:\n",
    "        continue\n",
    "    print(\"pdf index:\", idx, \"pages:\", len(img_list))\n",
    "    # layout detection and formula detection\n",
    "    doc_layout_result = []\n",
    "    latex_filling_list = []\n",
    "    mf_image_list = []\n",
    "    for idx, image in enumerate(img_list):\n",
    "        img_H, img_W = image.shape[0], image.shape[1]\n",
    "        layout_res = layout_model(image, ignore_catids=[])\n",
    "        layout_res['page_info'] = dict(\n",
    "            page_no = idx,\n",
    "            height = img_H,\n",
    "            width = img_W\n",
    "        )\n",
    "        doc_layout_result.append(layout_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_palette = [\n",
    "                (255,64,255),(255,255,0),(0,255,255),(255,215,135),(215,0,95),(100,0,48),(0,175,0),(95,0,95),(175,95,0),(95,95,0),\n",
    "                (95,95,255),(95,175,135),(215,95,0),(0,0,255),(0,255,0),(255,0,0),(0,95,215),(0,0,0),(0,0,0),(0,0,0)\n",
    "            ]\n",
    "id2names = [\"title\", \"plain_text\", \"abandon\", \"figure\", \"figure_caption\", \"table\", \"table_caption\", \"table_footnote\", \n",
    "            \"isolate_formula\", \"formula_caption\", \" \", \" \", \" \", \"inline_formula\", \"isolated_formula\", \"ocr_text\"]\n",
    "vis_pdf_result = []\n",
    "\n",
    "for idx, image in enumerate(img_list):\n",
    "    single_page_res = doc_layout_result[idx]['layout_dets']\n",
    "    vis_img = Image.new('RGB', Image.fromarray(image).size, 'white') if args.render else Image.fromarray(cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "    draw = ImageDraw.Draw(vis_img)\n",
    "    for res in single_page_res:\n",
    "        label = int(res['category_id'])\n",
    "        if label > 15:     # categories that do not need visualize\n",
    "            continue\n",
    "        label_name = id2names[label]\n",
    "        x_min, y_min = int(res['poly'][0]), int(res['poly'][1])\n",
    "        x_max, y_max = int(res['poly'][4]), int(res['poly'][5])\n",
    "        # we don't use the formule detection\n",
    "        draw.rectangle([x_min, y_min, x_max, y_max], fill=None, outline=color_palette[label], width=2)  # Increased outline width for better visibility\n",
    "        fontText = ImageFont.load_default()  # Use default font due to potential font loading issues\n",
    "        draw.text((x_min, y_min), label_name, fill=color_palette[label], font=fontText)  # Change 'color_palette' usage for fill\n",
    "    \n",
    "    width, height = vis_img.size\n",
    "    width, height = int(0.75*width), int(0.75*height)\n",
    "    vis_img = vis_img.resize((width, height))\n",
    "    vis_pdf_result.append(vis_img)\n",
    "        \n",
    "    first_page = vis_pdf_result.pop(0)\n",
    "    first_page.save(os.path.join(args.output, f'page_{idx}_layout.pdf'), 'PDF', resolution=100, save_all=True, append_images=vis_pdf_result)\n",
    "    import json\n",
    "\n",
    "    # Save single_page_res as a simple JSON file for each page\n",
    "    output_dir = args.output\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    for idx, single_page_res in enumerate(doc_layout_result):\n",
    "        with open(os.path.join(output_dir, f'page_{idx}_layout.json'), 'w') as json_file:\n",
    "            json.dump(single_page_res['layout_dets'], json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCR识别\n",
    "for idx, image in enumerate(img_list):\n",
    "    pil_img = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "    single_page_res = doc_layout_result[idx]['layout_dets']\n",
    "    single_page_mfdetrec_res = []\n",
    "    ocr_result = []\n",
    "\n",
    "    for res in single_page_res:\n",
    "        xmin, ymin = int(res['poly'][0]), int(res['poly'][1])\n",
    "        xmax, ymax = int(res['poly'][4]), int(res['poly'][5])\n",
    "        crop_box = [xmin, ymin, xmax, ymax]\n",
    "        cropped_img = Image.new('RGB', pil_img.size, 'white')\n",
    "        cropped_img.paste(pil_img.crop(crop_box), crop_box)\n",
    "        cropped_img = cv2.cvtColor(np.asarray(cropped_img), cv2.COLOR_RGB2BGR)\n",
    "        ocr_res = ocr_model.ocr(cropped_img, mfd_res=single_page_mfdetrec_res)[0]\n",
    "        if ocr_res:\n",
    "            res['ocr_result'] = []\n",
    "            for box_ocr_res in ocr_res:\n",
    "                p1, p2, p3, p4 = box_ocr_res[0]\n",
    "                text, score = box_ocr_res[1]\n",
    "                res['ocr_result'].append({\n",
    "                    'poly': p1 + p2 + p3 + p4,\n",
    "                    'score': round(score, 2),\n",
    "                    'text': text,\n",
    "                })\n",
    "        \n",
    "        output_dir = args.output\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "for idx, single_page_res in enumerate(doc_layout_result):\n",
    "    with open(os.path.join(output_dir, f'page_{idx}_ocr_result.json'), 'w') as json_file:\n",
    "        json.dump(single_page_res['layout_dets'], json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.device('cuda'):  \n",
    "\ttorch.cuda.empty_cache()  \n",
    "\ttorch.cuda.ipc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ocr and table recognition\n",
    "for idx, image in enumerate(img_list):\n",
    "    pil_img = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_RGB2BGR))\n",
    "    single_page_res = doc_layout_result[idx]['layout_dets']\n",
    "    single_page_mfdetrec_res = []\n",
    "    for res in single_page_res:\n",
    "        if int(res['category_id']) == 5: # table header, table, table footer \n",
    "            print('table here')\n",
    "            xmin, ymin = int(res['poly'][0]), int(res['poly'][1])\n",
    "            xmax, ymax = int(res['poly'][4]), int(res['poly'][5])\n",
    "            crop_box = [xmin, ymin, xmax, ymax]\n",
    "            cropped_img = pil_img.convert(\"RGB\").crop(crop_box)\n",
    "            start = time.time()\n",
    "            with torch.no_grad():\n",
    "                output = tr_model(cropped_img)\n",
    "            end = time.time()\n",
    "            if (end-start) > model_configs['model_args']['table_max_time']:\n",
    "                res[\"timeout\"] = True\n",
    "            res[\"latex_result\"] = output[0]\n",
    "    \n",
    "for idx, single_page_res in enumerate(doc_layout_result):\n",
    "    with open(os.path.join(output_dir, f'page_{idx}_orc_table_result.json'), 'w') as json_file:\n",
    "        json.dump(single_page_res['layout_dets'], json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{@{}lccc@{}}\\toprule\\textbf{Variable} & \\textbf{Pre} & \\textbf{ during} & \\textbf{P value} \\\\\\midrule \\textbf{Klocsiories} & \\textbf{$2185 \\pm 94$} & \\textbf{$172 \\pm 85$} & \\textbf{00005} \\\\\\textbf{Prouen(g)} & \\textbf{$92 \\pm 6$} & \\textbf{$62 \\pm 5$} & \\textbf{00003} \\\\\\textbf{Prouen(R){\\tiny 图} } & \\textbf{17 \\pm 0} & \\textbf{13 \\pm 0} & \\textbf{0004} \\\\\\textbf{Carbohydrate(g)} & \\textbf{287 \\pm I4} & \\textbf{269 \\pm 17} & \\textbf{041} \\\\\\textbf{Carbohydrate(g)} & \\textbf{33 \\pm 0} & \\textbf{62 \\pm 0} & \\textbf{00002} \\\\\\textbf{Faber(g)} & \\textbf{26 \\pm 2} & \\textbf{40 \\pm 3} & \\textbf{$< 00001$} \\\\\\textbf{Sugar(g)} & \\textbf{96 \\pm 7} & \\textbf{88 \\pm 6} & \\textbf{037} \\\\\\textbf{Fat(g)} & \\textbf{74 \\pm 5} & \\textbf{54 \\pm 4} & \\textbf{0003} \\\\\\textbf{Fat(G)} & \\textbf{30 \\pm 0} & \\textbf{27 \\pm 0} & \\textbf{020} \\\\\\textbf{SaturatedFat(g)} & \\textbf{24 \\pm 2} & \\textbf{9 \\pm 1} & \\textbf{$< 00001$} \\\\\\textbf{MonoursarvatedFat(g)} & \\textbf{14 \\pm 2} & \\textbf{14 \\pm 2} & \\textbf{089} \\\\\\textbf{PopyrsaturatedFat(g)} & \\textbf{$8 \\pm 1$} & \\textbf{$9 \\pm 1$} & \\textbf{047} \\\\\\textbf{TransFIR(g)} & \\textbf{1 \\pm 0} & \\textbf{$0 \\pm 0$} & \\textbf{0006} \\\\\\textbf{Onequa3(g)} & \\textbf{711 \\pm 163} & \\textbf{78. \\pm 202} & \\textbf{077} \\\\\\textbf{Onequa6(g)} & \\textbf{230 \\pm 37} & \\textbf{334 \\pm 345} & \\textbf{010} \\\\\\textbf{Cholesterol(g)} & \\textbf{225 \\pm 19} & \\textbf{28 \\pm 20} & \\textbf{$< 00001$} \\\\\\textbf{VfaminC(g)} & \\textbf{70 \\pm 9} & \\textbf{119 \\pm 12} & \\textbf{0002} \n",
      "\\begin{tabular}{@{}lccc@{}}\\hline \\hline \\textbf{\\tiny 标志} & \\phantom{ab} & \\textbf{\\tiny In} & \\phantom{ab} & \\textbf{\\tiny Post} \\\\\\hline \\textbf{\\tiny Onosteol(mgdt)''} && \\textbf{\\tiny 1/11\\,±\\,46} && \\textbf{\\tiny 1387\\,±\\,44} \\\\\\textbf{\\tiny 70lycerodes(mgdt)''} && \\textbf{\\tiny 85.1\\,±\\,48} && \\textbf{\\tiny 753\\,±\\,36} \\\\\\textbf{\\tiny Hol-C(mgdt)''} && \\textbf{\\tiny 556\\,±\\,23} && \\textbf{\\tiny 476\\,±\\,22} \\\\\\textbf{\\tiny MDL-C(mgdt)''} && \\textbf{\\tiny 170\\,±\\,10} && \\textbf{\\tiny 180\\,±\\,07} \\\\\\textbf{\\tiny DDLC(mgdt)''} && \\textbf{\\tiny 984\\,±\\,39} && \\textbf{\\tiny 761\\,±\\,35} \\\\\\textbf{\\tiny Fina+DL-C} && \\textbf{\\tiny 13\\,±\\,0]} && \\textbf{\\tiny 11\\,±\\,01} \\\\\\hline \\hline \\end{tabular}\n",
      "\\begin{tabular}{|p{0.25\\columnwidth}|p{0.25\\columnwidth}|p{0.25\\columnwidth}|p{0.25\\columnwidth}|p{0.25\\columnwidth}|}\\hline $\\texttt{a}$ & \\multicolumn{2}{l|}{$\\texttt{b}$} \\\\ \\cline{2-3} & $\\texttt{c}$ & $\\texttt{d}$ \\\\ \\cline{1-3}\\multicolumn{3}{|l|}{$\\texttt{e}$} \\\\ \\hline \\end{tabular}\n",
      "\\begin{tabular}{p{0.35\\linewidth}|p{0.28\\linewidth}p{0.28\\linewidth}p{0.28\\linewidth}}\\hline \\sf Header Col 1& \\sf Header Col 2&\\\\\\hline \\sf Lorem ipsum & \\textcolor{blue}{A link example} \\\\\\hline \\end{tabular}\n",
      "\\begin{tabular}{p{0.2\\columnwidth}|p{0.167\\columnwidth}|p{0.167\\columnwidth}|p{0.167\\columnwidth}|p{0.167\\columnwidth}}\\hline \\texttt{a} & \\multicolumn{2}{l|}{\\texttt{>b<}} & \\texttt{c} \\\\ \\hline \\cline{2-3}\\texttt{d} & \\texttt{e} & \\texttt{f} & \\texttt{i} \\\\ \\cline{2-3} & \\texttt{g8t} & \\texttt{h} & \\\\ \\hline \\texttt{j} & \\multicolumn{2}{l|}{\\texttt{k}} & \\texttt{l} \\\\ \\hline \\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "for idx, single_page_res in enumerate(doc_layout_result):\n",
    "    for res_index, res in enumerate(single_page_res['layout_dets']):\n",
    "        if 'latex_result' in res and int(res['category_id']) == 5:\n",
    "            latex = res['latex_result']\n",
    "            print(latex)\n",
    "            latex_image = tex2pil(latex)[0]\n",
    "            latex_image.save(os.path.join(output_dir,f'page_{idx}_latex_image_{res_index}.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ocr_result(ocr_reuslt):\n",
    "    ocr_result_ordered = []\n",
    "    for res in ocr_result:\n",
    "        xmin, ymin = int(res['poly'][0]), int(res['poly'][1])\n",
    "        xmax, ymax = int(res['poly'][4]), int(res['poly'][5])\n",
    "        x_avg = (xmin + xmax)/2\n",
    "        y_avg = (ymin + ymax)/2\n",
    "        text = res['text']\n",
    "        ocr_result_ordered.append((x_avg,y_avg,text))\n",
    "    return ocr_result_ordered\n",
    "\n",
    "doc_llm= []\n",
    "for idx, page in enumerate(doc_layout_result):\n",
    "    res_llm = []\n",
    "    layout = page['layout_dets']\n",
    "    for res in layout:\n",
    "        layout_llm = {}\n",
    "        xmin, ymin = int(res['poly'][0]), int(res['poly'][1])\n",
    "        xmax, ymax = int(res['poly'][4]), int(res['poly'][5])\n",
    "        x_avg = (xmin + xmax)/2\n",
    "        y_avg = (ymin + ymax)/2\n",
    "        layout_llm['center_position'] = (x_avg,y_avg)\n",
    "        layout_llm['box_position'] = (xmin,ymin,xmax,ymax)\n",
    "\n",
    "        category_id = res['category_id']\n",
    "        layout_llm['category'] = id2names[category_id]\n",
    "        if 'ocr_result' in res :\n",
    "            ocr_result = res['ocr_result']\n",
    "            layout_llm['ocr_result'] = process_ocr_result(ocr_result)\n",
    "        if 'latex_result' in res:\n",
    "            latex_result = res['latex_result']\n",
    "            layout_llm['latex_result'] = latex_result\n",
    "        res_llm.append(layout_llm)\n",
    "    doc_llm.append(res_llm)\n",
    "\n",
    "# for idx, single_page_res in enumerate(doc_llm):\n",
    "#     with open(os.path.join(output_dir, f'page_{idx}_llm_result.json'), 'w') as json_file:\n",
    "#         json.dump(single_page_res, json_file, indent=4)\n",
    "\n",
    "# with open('/output/doc_llm.json', 'w') as f:\n",
    "#     json.dump(doc_llm, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'latex_2': \"\\\\begin{tabular}{@{}lccc@{}}\\\\hline \\\\hline \\\\textbf{\\\\tiny 标志} & \\\\phantom{ab} & \\\\textbf{\\\\tiny In} & \\\\phantom{ab} & \\\\textbf{\\\\tiny Post} \\\\\\\\\\\\hline \\\\textbf{\\\\tiny Onosteol(mgdt)''} && \\\\textbf{\\\\tiny 1/11\\\\,±\\\\,46} && \\\\textbf{\\\\tiny 1387\\\\,±\\\\,44} \\\\\\\\\\\\textbf{\\\\tiny 70lycerodes(mgdt)''} && \\\\textbf{\\\\tiny 85.1\\\\,±\\\\,48} && \\\\textbf{\\\\tiny 753\\\\,±\\\\,36} \\\\\\\\\\\\textbf{\\\\tiny Hol-C(mgdt)''} && \\\\textbf{\\\\tiny 556\\\\,±\\\\,23} && \\\\textbf{\\\\tiny 476\\\\,±\\\\,22} \\\\\\\\\\\\textbf{\\\\tiny MDL-C(mgdt)''} && \\\\textbf{\\\\tiny 170\\\\,±\\\\,10} && \\\\textbf{\\\\tiny 180\\\\,±\\\\,07} \\\\\\\\\\\\textbf{\\\\tiny DDLC(mgdt)''} && \\\\textbf{\\\\tiny 984\\\\,±\\\\,39} && \\\\textbf{\\\\tiny 761\\\\,±\\\\,35} \\\\\\\\\\\\textbf{\\\\tiny Fina+DL-C} && \\\\textbf{\\\\tiny 13\\\\,±\\\\,0]} && \\\\textbf{\\\\tiny 11\\\\,±\\\\,01} \\\\\\\\\\\\hline \\\\hline \\\\end{tabular}\", 'latex_6': '\\\\begin{tabular}{@{}lccc@{}}\\\\toprule\\\\textbf{Variable} & \\\\textbf{Pre} & \\\\textbf{ during} & \\\\textbf{P value} \\\\\\\\\\\\midrule \\\\textbf{Klocsiories} & \\\\textbf{$2185 \\\\pm 94$} & \\\\textbf{$172 \\\\pm 85$} & \\\\textbf{00005} \\\\\\\\\\\\textbf{Prouen(g)} & \\\\textbf{$92 \\\\pm 6$} & \\\\textbf{$62 \\\\pm 5$} & \\\\textbf{00003} \\\\\\\\\\\\textbf{Prouen(R){\\\\tiny 图} } & \\\\textbf{17 \\\\pm 0} & \\\\textbf{13 \\\\pm 0} & \\\\textbf{0004} \\\\\\\\\\\\textbf{Carbohydrate(g)} & \\\\textbf{287 \\\\pm I4} & \\\\textbf{269 \\\\pm 17} & \\\\textbf{041} \\\\\\\\\\\\textbf{Carbohydrate(g)} & \\\\textbf{33 \\\\pm 0} & \\\\textbf{62 \\\\pm 0} & \\\\textbf{00002} \\\\\\\\\\\\textbf{Faber(g)} & \\\\textbf{26 \\\\pm 2} & \\\\textbf{40 \\\\pm 3} & \\\\textbf{$< 00001$} \\\\\\\\\\\\textbf{Sugar(g)} & \\\\textbf{96 \\\\pm 7} & \\\\textbf{88 \\\\pm 6} & \\\\textbf{037} \\\\\\\\\\\\textbf{Fat(g)} & \\\\textbf{74 \\\\pm 5} & \\\\textbf{54 \\\\pm 4} & \\\\textbf{0003} \\\\\\\\\\\\textbf{Fat(G)} & \\\\textbf{30 \\\\pm 0} & \\\\textbf{27 \\\\pm 0} & \\\\textbf{020} \\\\\\\\\\\\textbf{SaturatedFat(g)} & \\\\textbf{24 \\\\pm 2} & \\\\textbf{9 \\\\pm 1} & \\\\textbf{$< 00001$} \\\\\\\\\\\\textbf{MonoursarvatedFat(g)} & \\\\textbf{14 \\\\pm 2} & \\\\textbf{14 \\\\pm 2} & \\\\textbf{089} \\\\\\\\\\\\textbf{PopyrsaturatedFat(g)} & \\\\textbf{$8 \\\\pm 1$} & \\\\textbf{$9 \\\\pm 1$} & \\\\textbf{047} \\\\\\\\\\\\textbf{TransFIR(g)} & \\\\textbf{1 \\\\pm 0} & \\\\textbf{$0 \\\\pm 0$} & \\\\textbf{0006} \\\\\\\\\\\\textbf{Onequa3(g)} & \\\\textbf{711 \\\\pm 163} & \\\\textbf{78. \\\\pm 202} & \\\\textbf{077} \\\\\\\\\\\\textbf{Onequa6(g)} & \\\\textbf{230 \\\\pm 37} & \\\\textbf{334 \\\\pm 345} & \\\\textbf{010} \\\\\\\\\\\\textbf{Cholesterol(g)} & \\\\textbf{225 \\\\pm 19} & \\\\textbf{28 \\\\pm 20} & \\\\textbf{$< 00001$} \\\\\\\\\\\\textbf{VfaminC(g)} & \\\\textbf{70 \\\\pm 9} & \\\\textbf{119 \\\\pm 12} & \\\\textbf{0002} '}\n",
      "# Document\n",
      "\n",
      "## References\n",
      "\n",
      "Blomert lpids in Health and Disease 2010;9:94\n",
      "\n",
      "http://www.lipidworld.com/content/9/1/94\n",
      "\n",
      "## Table 4: Lipid Panel Data\n",
      "\n",
      "Lipid panel data of men and women before and after a 21-day Daniel Fast.\n",
      "\n",
      "\\begin{tabular}{@{}lccc@{}}\\hline \\hline \\textbf{\\tiny 标志} & \\phantom{ab} & \\textbf{\\tiny In} & \\phantom{ab} & \\textbf{\\tiny Post} \\\\\\hline \\textbf{\\tiny Onosteol(mgdt)''} && \\textbf{\\tiny 1/11\\,±\\,46} && \\textbf{\\tiny 1387\\,±\\,44} \\\\\\textbf{\\tiny 70lycerodes(mgdt)''} && \\textbf{\\tiny 85.1\\,±\\,48} && \\textbf{\\tiny 753\\,±\\,36} \\\\\\textbf{\\tiny Hol-C(mgdt)''} && \\textbf{\\tiny 556\\,±\\,23} && \\textbf{\\tiny 476\\,±\\,22} \\\\\\textbf{\\tiny MDL-C(mgdt)''} && \\textbf{\\tiny 170\\,±\\,10} && \\textbf{\\tiny 180\\,±\\,07} \\\\\\textbf{\\tiny DDLC(mgdt)''} && \\textbf{\\tiny 984\\,±\\,39} && \\textbf{\\tiny 761\\,±\\,35} \\\\\\textbf{\\tiny Fina+DL-C} && \\textbf{\\tiny 13\\,±\\,0]} && \\textbf{\\tiny 11\\,±\\,01} \\\\\\hline \\hline \\end{tabular}\n",
      "\n",
      "### Notes:\n",
      "- Values are mean ± SEM.\n",
      "- P<0.0001, \"p=0.02\", \"p=0.0004\"\n",
      "- No other statistically significant differences noted (p>0.05).\n",
      "\n",
      "## Study Results\n",
      "\n",
      "1. Significantly reduced blood pressure.\n",
      "2. Significantly reduces total cholesterol, LDL, and HDL cholesterol.\n",
      "3. Reduces insulin, HOMA-IR, and C-reactive protein in a clinically meaningful, but statistically insignificant manner.\n",
      "4. Does not cause any negative effects on blood count or metabolic panel values.\n",
      "5. Is well-tolerated.\n",
      "6. May be useful as a nutrition education tool for men and women.\n",
      "\n",
      "To our knowledge, this is the first scientific investigation of the Daniel Fast. Subsequent statistical analyses indicated no interactions between normal weight and overweight/obese subjects, men and women, and exercise-trained and untrained subjects, suggesting that a wide variety of individuals may benefit from a dietary approach in accordance with the Daniel Fast.\n",
      "\n",
      "## Table 5: Dietary Data\n",
      "\n",
      "Dietary data of men and women before and during the final seven days of a 21-day Daniel Fast.\n",
      "\n",
      "\\begin{tabular}{@{}lccc@{}}\\toprule\\textbf{Variable} & \\textbf{Pre} & \\textbf{ during} & \\textbf{P value} \\\\\\midrule \\textbf{Klocsiories} & \\textbf{$2185 \\pm 94$} & \\textbf{$172 \\pm 85$} & \\textbf{00005} \\\\\\textbf{Prouen(g)} & \\textbf{$92 \\pm 6$} & \\textbf{$62 \\pm 5$} & \\textbf{00003} \\\\\\textbf{Prouen(R){\\tiny 图} } & \\textbf{17 \\pm 0} & \\textbf{13 \\pm 0} & \\textbf{0004} \\\\\\textbf{Carbohydrate(g)} & \\textbf{287 \\pm I4} & \\textbf{269 \\pm 17} & \\textbf{041} \\\\\\textbf{Carbohydrate(g)} & \\textbf{33 \\pm 0} & \\textbf{62 \\pm 0} & \\textbf{00002} \\\\\\textbf{Faber(g)} & \\textbf{26 \\pm 2} & \\textbf{40 \\pm 3} & \\textbf{$< 00001$} \\\\\\textbf{Sugar(g)} & \\textbf{96 \\pm 7} & \\textbf{88 \\pm 6} & \\textbf{037} \\\\\\textbf{Fat(g)} & \\textbf{74 \\pm 5} & \\textbf{54 \\pm 4} & \\textbf{0003} \\\\\\textbf{Fat(G)} & \\textbf{30 \\pm 0} & \\textbf{27 \\pm 0} & \\textbf{020} \\\\\\textbf{SaturatedFat(g)} & \\textbf{24 \\pm 2} & \\textbf{9 \\pm 1} & \\textbf{$< 00001$} \\\\\\textbf{MonoursarvatedFat(g)} & \\textbf{14 \\pm 2} & \\textbf{14 \\pm 2} & \\textbf{089} \\\\\\textbf{PopyrsaturatedFat(g)} & \\textbf{$8 \\pm 1$} & \\textbf{$9 \\pm 1$} & \\textbf{047} \\\\\\textbf{TransFIR(g)} & \\textbf{1 \\pm 0} & \\textbf{$0 \\pm 0$} & \\textbf{0006} \\\\\\textbf{Onequa3(g)} & \\textbf{711 \\pm 163} & \\textbf{78. \\pm 202} & \\textbf{077} \\\\\\textbf{Onequa6(g)} & \\textbf{230 \\pm 37} & \\textbf{334 \\pm 345} & \\textbf{010} \\\\\\textbf{Cholesterol(g)} & \\textbf{225 \\pm 19} & \\textbf{28 \\pm 20} & \\textbf{$< 00001$} \\\\\\textbf{VfaminC(g)} & \\textbf{70 \\pm 9} & \\textbf{119 \\pm 12} & \\textbf{0002} \n",
      "\n",
      "## Additional Insights\n",
      "\n",
      "- Training status comparisons in this initial study, coupled with the fact that no interactions were noted for any of the above-mentioned comparisons, only pooled data are presented in the tables and discussed within this manuscript.\n",
      "\n",
      "- It is important to note that our findings reference relatively healthy, young to middle-age men and women (age range: 20-62 years), with a wide BMI range (18.0 kg/m² to 40.6 kg/m²) and varied regular exercise and dietary habits. We noted similar findings in all subject groups:\n",
      "  - Similar percent changes in all measured variables from pre to post-fast were observed in normal weight, regular exercisers, and those who eat a clean diet.\n",
      "  - However, absolute values were better for normal weight, exercise enthusiasts compared to overweight/obese, sedentary subjects.\n",
      "\n",
      "- Based on our findings, individuals with diagnosed metabolic and cardiovascular disorders may experience clinically meaningful results on such a dietary regimen. Future work should include such patients as this diet may be considered an anti-inflammatory, anti-atherogenic, anti-hypertensive, non-pharmacologic approach to disease risk management.\n",
      "\n",
      "## Observations\n",
      "\n",
      "- While there was a reduction of blood pressure, and decreases in total (19%) and LDL cholesterol (23%) similar to those noted for other plant-based diets, HDL cholesterol also decreased (14%).\n",
      "- If this eating plan is considered \"heart healthy,\" future studies should include specific food choices or supplements that increase HDL-C to maintain this while decreasing total and LDL-C.\n",
      "\n",
      "- Aside from HDL-C, decreases in insulin (24%), HOMA-IR (26%), and C-reactive protein (49%) were not statistically significant. A post hoc power analysis indicated a larger sample size might achieve statistical significance.\n",
      "\n",
      "- Future studies should include a larger sample size to improve the chance of achieving statistical significance for these variables.\n",
      "{'latex_2': '\\\\begin{tabular}{p{0.35\\\\linewidth}|p{0.28\\\\linewidth}p{0.28\\\\linewidth}p{0.28\\\\linewidth}}\\\\hline \\\\sf Header Col 1& \\\\sf Header Col 2&\\\\\\\\\\\\hline \\\\sf Lorem ipsum & \\\\textcolor{blue}{A link example} \\\\\\\\\\\\hline \\\\end{tabular}', 'latex_4': '\\\\begin{tabular}{p{0.2\\\\columnwidth}|p{0.167\\\\columnwidth}|p{0.167\\\\columnwidth}|p{0.167\\\\columnwidth}|p{0.167\\\\columnwidth}}\\\\hline \\\\texttt{a} & \\\\multicolumn{2}{l|}{\\\\texttt{>b<}} & \\\\texttt{c} \\\\\\\\ \\\\hline \\\\cline{2-3}\\\\texttt{d} & \\\\texttt{e} & \\\\texttt{f} & \\\\texttt{i} \\\\\\\\ \\\\cline{2-3} & \\\\texttt{g8t} & \\\\texttt{h} & \\\\\\\\ \\\\hline \\\\texttt{j} & \\\\multicolumn{2}{l|}{\\\\texttt{k}} & \\\\texttt{l} \\\\\\\\ \\\\hline \\\\end{tabular}', 'latex_6': '\\\\begin{tabular}{|p{0.25\\\\columnwidth}|p{0.25\\\\columnwidth}|p{0.25\\\\columnwidth}|p{0.25\\\\columnwidth}|p{0.25\\\\columnwidth}|}\\\\hline $\\\\texttt{a}$ & \\\\multicolumn{2}{l|}{$\\\\texttt{b}$} \\\\\\\\ \\\\cline{2-3} & $\\\\texttt{c}$ & $\\\\texttt{d}$ \\\\\\\\ \\\\cline{1-3}\\\\multicolumn{3}{|l|}{$\\\\texttt{e}$} \\\\\\\\ \\\\hline \\\\end{tabular}'}\n",
      "# Simple Uniform Table\n",
      "\n",
      "\\begin{tabular}{p{0.35\\linewidth}|p{0.28\\linewidth}p{0.28\\linewidth}p{0.28\\linewidth}}\\hline \\sf Header Col 1& \\sf Header Col 2&\\\\\\hline \\sf Lorem ipsum & \\textcolor{blue}{A link example} \\\\\\hline \\end{tabular}\n",
      "\n",
      "# Nested Table\n",
      "\n",
      "\\begin{tabular}{p{0.2\\columnwidth}|p{0.167\\columnwidth}|p{0.167\\columnwidth}|p{0.167\\columnwidth}|p{0.167\\columnwidth}}\\hline \\texttt{a} & \\multicolumn{2}{l|}{\\texttt{>b<}} & \\texttt{c} \\\\ \\hline \\cline{2-3}\\texttt{d} & \\texttt{e} & \\texttt{f} & \\texttt{i} \\\\ \\cline{2-3} & \\texttt{g8t} & \\texttt{h} & \\\\ \\hline \\texttt{j} & \\multicolumn{2}{l|}{\\texttt{k}} & \\texttt{l} \\\\ \\hline \\end{tabular}\n",
      "\n",
      "# Table with Merged Cells\n",
      "\n",
      "\\begin{tabular}{|p{0.25\\columnwidth}|p{0.25\\columnwidth}|p{0.25\\columnwidth}|p{0.25\\columnwidth}|p{0.25\\columnwidth}|}\\hline $\\texttt{a}$ & \\multicolumn{2}{l|}{$\\texttt{b}$} \\\\ \\cline{2-3} & $\\texttt{c}$ & $\\texttt{d}$ \\\\ \\cline{1-3}\\multicolumn{3}{|l|}{$\\texttt{e}$} \\\\ \\hline \\end{tabular}\n",
      "\n",
      "# Budget\n",
      "\n",
      "The budget for the current school year was distributed by Richard Miller, PTA Treasurer, and reviewed by the board and PTA members at the last meeting. In tonight's meeting, Steve Watson made a motion to approve the budget which was seconded by Harry Anderson. All presents voted in favor of approving the budget as presented.\n",
      "\n",
      "# Principal's Report\n",
      "\n",
      "Principal Samuel Pattison presented his report.\n",
      "\n",
      "# New Business\n",
      "\n",
      "· Recap of Back to School night - May 9\n",
      "\n",
      "· Parent Education Programs - Counselors\n",
      "\n",
      "· Teacher Grants Application Process - [School Name]\n",
      "\n",
      "# Committee Reports\n",
      "\n",
      "· Membership\n",
      "\n",
      "· Volunteers\n",
      "\n",
      "· Newsletter\n",
      "\n",
      "· Computer Support\n"
     ]
    }
   ],
   "source": [
    "def double_column_sort(data):\n",
    "    # 分组\n",
    "    group1 = [item for item in data if item['center_position'][0] < 800]\n",
    "    group2 = [item for item in data if item['center_position'][0] >= 800]\n",
    "\n",
    "    # 按照 center_position 的第二个元素进行排序\n",
    "    group1_sorted = sorted(group1, key=lambda x: x['center_position'][1])\n",
    "    group2_sorted = sorted(group2, key=lambda x: x['center_position'][1])\n",
    "\n",
    "    # 合并排序后的两组\n",
    "    return group1_sorted + group2_sorted\n",
    "\n",
    "import copy\n",
    "for idx,single_page_llm in enumerate(doc_llm):\n",
    "    if idx == 0:\n",
    "        continue\n",
    "    DocAnalysePrompt = \"\"\"你是一个文本分析大师，你需要将一个杂乱的文本内容转化为有条理的markdown结构\n",
    "    我们规定文本的左上角为0,0 其中x表示从左往右依次增大，y表示从上到下依次增大\n",
    "\n",
    "    我们会输入一个list，其中的item都是的下面的结构：\n",
    "    {'center_position': (x_avg,y_avg),\n",
    "    'box_position': (xmin,ymin,xmax,ymax),\n",
    "    'category': 'category',包含文本，标题等\n",
    "    'ocr_result': [(x_avg, y_avg, ocr_result)]\n",
    "    'latex_result' : 'latex'}\n",
    "    ocr_result是一个list，里面是一个三元组(x_avg, y_avg, ocr_result)，里面ocr_result就是识别到的文本内容。\n",
    "    这里面的ocr_result会有重叠的部分，你要根据对应的x_avg y_avg判断这些内容是不是重复的，并且忽略掉重复的部分\n",
    "\n",
    "    你需要分析这个文本的结构，例如：是单栏，双栏或者是其他结构\n",
    "    \"\"\"\n",
    "    from pydantic import BaseModel\n",
    "    from enum import Enum\n",
    "\n",
    "    class ColumnType(str, Enum):\n",
    "        single_column = \"single_column\"\n",
    "        double_column = \"double_column\"\n",
    "        others = \"others\"\n",
    "        \n",
    "    class DocAnalyseResponseFormat(BaseModel):\n",
    "        very_short_analysis : str\n",
    "        ColumnType : ColumnType\n",
    "\n",
    "    from utils import openai_wrapper\n",
    "    DocAnalysePage = [{'center_position': item['center_position'], 'box_position': item['box_position'], 'category': item['category']} for item in single_page_llm]\n",
    "\n",
    "    DocAnalyse_result =  openai_wrapper(DocAnalysePrompt,DocAnalysePage,DocAnalyseResponseFormat,model=\"gpt-4o-2024-08-06\")\n",
    "\n",
    "    # reduce the amount of the pages:\n",
    "    if DocAnalyse_result.ColumnType is ColumnType.single_column:\n",
    "        page = copy.deepcopy(single_page_llm)\n",
    "        page = sorted(page, key=lambda x: x['center_position'][1])\n",
    "\n",
    "        name2latex = {}\n",
    "        latex_name_list = []\n",
    "        for index,item in enumerate(page):\n",
    "            if 'box_position' in item : del item['box_position']\n",
    "            if 'center_position' in item : del item['center_position']\n",
    "            if 'latex_result' in item:\n",
    "                name2latex[f\"latex_{index}\"] = item['latex_result']\n",
    "                latex_name_list.append(f\"latex_{index}\")\n",
    "                item['latex_result'] = f\"latex_{index}\"\n",
    "                if 'ocr_result' in item:\n",
    "                    del item['ocr_result']\n",
    "            else :\n",
    "                if \"ocr_result\" in item : item['ocr_result'] = sorted( item['ocr_result'], key=lambda x: x[1])\n",
    "    elif DocAnalyse_result.ColumnType is ColumnType.double_column:\n",
    "        page = copy.deepcopy(single_page_llm)\n",
    "        page = double_column_sort(page)\n",
    "\n",
    "        name2latex = {}\n",
    "        latex_name_list = []\n",
    "        for index,item in enumerate(page):\n",
    "            if 'box_position' in item : del item['box_position']\n",
    "            # if 'center_position' in item : del item['center_position']\n",
    "            if 'latex_result' in item:\n",
    "                name2latex[f\"latex_{index}\"] = item['latex_result']\n",
    "                latex_name_list.append(f\"latex_{index}\")\n",
    "                item['latex_result'] = f\"latex_{index}\"\n",
    "                if 'ocr_result' in item:\n",
    "                    del item['ocr_result']\n",
    "            else :\n",
    "                if \"ocr_result\" in item : item['ocr_result'] = sorted( item['ocr_result'], key=lambda x: x[1])\n",
    "    \n",
    "    else:\n",
    "        break\n",
    "\n",
    "\n",
    "    print(name2latex)\n",
    "    DocWritePrompt = \"\"\"你是一个文本格式化机，你需要将一个杂乱的文本内容转化为有条理的markdown结构，你不会遗漏原文中的任何信息\n",
    "我们规定文本的左上角为0,0,我们使用(x,y)来表示位置 其中x表示从左往右依次增大，y表示从上到下依次增大\n",
    "\n",
    "我们会输入一个list，其中的item都是的下面的结构：\n",
    "{'category': 'category',包含文本，标题等\n",
    "'ocr_result': [(x_avg, y_avg, ocr_result)]\n",
    "'latex_result' : 'latex_i'}\n",
    "ocr_result是一个list，里面是一个三元组(x_avg, y_avg, ocr_result)，里面ocr_result就是识别到的文本内容。在这里面你也是要根据对应的y_avg去判断元素所应该在的位置\n",
    "这里面的ocr_result会有重叠的部分，你要根据对应的x_avg y_avg判断这些内容是不是重复的，并且忽略掉重复的部分\n",
    "你要注意其中我们对于其中的图表使用了{latex_list}去进行替代，你要在对应的位置使用####latex_i####来代替对应的图表。\n",
    "请你注意我们的category识别可能是会有问题的，你要对这里面的明显错误去进行纠正\n",
    "你要将文本中提到的内容都严格地完成地返回，不要遗漏任何内容，不要省略任何内容，\n",
    "\n",
    "错误示例：\n",
    "没有将内容都返回，反而给出了省略号，同时返回了不存在的图表\n",
    "# title\n",
    "....\n",
    "####latex_i####\n",
    "# next title\n",
    "没有严格按照原文本的内容返回，而是添加了其他的内容\n",
    "正确示例：\n",
    "# title\n",
    "the text from the input \n",
    "####latex_1#### 要展示的图表\n",
    "请你务必严格遵守上面的规则，否则我会失去这份工作\n",
    "\"\"\"\n",
    "    from pydantic import BaseModel\n",
    "        \n",
    "    class DocWriteResponseFormat(BaseModel):\n",
    "        markdown : str\n",
    "        \n",
    "    DocWritePrompt = DocWritePrompt.replace(\"{latex_list}\", str(latex_name_list))\n",
    "\n",
    "    result =  openai_wrapper(DocWritePrompt,f\"input text : {page}\",DocWriteResponseFormat,model=\"gpt-4o-2024-08-06\")\n",
    "\n",
    "    pattern = r\"####(latex_\\d+)####\"\n",
    "    markdown_result = result.markdown\n",
    "\n",
    "    def post_process_replace(pattern,replace_dict,markdown_result):\n",
    "        import re\n",
    "        filtered_result = re.sub(pattern, lambda match: replace_dict.get(match.group(1), match.group(0)), markdown_result)\n",
    "        return filtered_result\n",
    "    final_result = post_process_replace(pattern,name2latex,markdown_result)\n",
    "    print(final_result)\n",
    "\n",
    "    with open(os.path.join(output_dir, f'page_{idx}_openai.md'), 'w') as file:\n",
    "        file.write(final_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "docparse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
